{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOGsWdI5Tpsl+cVwZlHQaYr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PWh64YOuQcaj"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import cv2\n","\n","import glob\n","import matplotlib.pyplot as plt\n","\n","import tensorflow.keras.layers as tfl\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import  Dense, BatchNormalization, ReLU, Dropout, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Add, GlobalAveragePooling2D, concatenate#, Average, Concatenate, SpatialDropout2D\n","from tensorflow.keras.regularizers import L1L2\n","from tensorflow.keras import Input,models\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","from sklearn.model_selection import train_test_split\n","\n","import imgaug as ia\n","import imgaug.augmenters as iaa\n","\n","from google.colab import drive\n","from google.colab import files\n"]},{"cell_type":"code","source":["drive.mount(\"/content/drive\", force_remount=True)\n","%cd drive/MyDrive/Colab Notebooks/"],"metadata":{"id":"0DozIppPQe1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_encoder = {\"Basketball\" : 0, \"Football\" : 1, \"Rowing\" : 2, \"Swimming\" : 3, \"Tennis\" : 4, \"Yoga\" : 5}"],"metadata":{"id":"C0fsVibgTvew"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["augmentation = iaa.Sequential([\n","    # 1. Flip\n","    iaa.Fliplr(0.5),\n","    # 2. Affine\n","    iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n","               rotate=(-10, 10),\n","               scale=(0.8, 1.2)),\n","               \n","    # 3. Multiply\n","    iaa.Multiply((0.8, 1.2)),\n","    # 4. Linearcontrast\n","    iaa.LinearContrast((0.8, 1.2)),\n","    # Perform methods below only sometimes\n","    iaa.Sometimes(0.7,\n","        # 5. GaussianBlur\n","        iaa.GaussianBlur((0.1, 0.6))\n","        )\n","])\n"],"metadata":{"id":"g_A-C_pSQjRP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imgsP1 = glob.glob(f\"./NN_DataSet/Train/*\")\n","TrainImgs = []\n","TrainLabel = []\n","# x = 325 , y = 420\n","for f in imgsP1: \n","  img = cv2.imread(f)\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  # img = img.astype(np.float32)\n","  img = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n","\n","  l = label_encoder[f.split('/')[3].split('_')[0]]\n","\n","  TrainImgs.append(img)#/255\n","  TrainLabel.append(l)\n","  # n = 3 if l == 0 else 2\n","  # for i in range(n):\n","  #   augmented_img = augmentation(image=img)\n","  #   TrainImgs.append(augmented_img/255)\n","  #   TrainLabel.append(l)\n","\n","\n","TrainImgs = np.array(TrainImgs)\n","TrainLabel = np.reshape(TrainLabel,(-1,1))\n","del imgsP1"],"metadata":{"id":"025s-KGIQlnG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(TrainImgs, TrainLabel, test_size=0.2, random_state=10)"],"metadata":{"id":"kPmVfJ-7QnsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datagen = ImageDataGenerator(\n","    rotation_range=10,\n","    rescale=1./255,\n","    width_shift_range=[-0.05, 0.05],\n","    height_shift_range=[-0.05, 0.05],\n","    horizontal_flip=True,\n","    brightness_range=[0.9,1.1],\n","    zoom_range=[-0.1,0.1],\n","    # fill_mode = \"wrap\"\n","    )"],"metadata":{"id":"pZrocHxFeQ2H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datagen.fit(X_train)"],"metadata":{"id":"jypt5g8CedIf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape, X_test.shape"],"metadata":{"id":"D0cooyEOQqc-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del TrainImgs\n","del TrainLabel"],"metadata":{"id":"pHQ3ozwOQqyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(X_train[77,:])"],"metadata":{"id":"rYrW7SdVQv62"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4): \n","  # 1st path:\n","  path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n","\n","  # 2nd path\n","  path2 = Conv2D(filters = f2_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n","  path2 = Conv2D(filters = f2_conv3, kernel_size = (3,3), padding = 'same', activation = 'relu')(path2)\n","\n","  # 3rd path\n","  path3 = Conv2D(filters = f3_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n","  path3 = Conv2D(filters = f3_conv5, kernel_size = (5,5), padding = 'same', activation = 'relu')(path3)\n","\n","  # 4th path\n","  path4 = MaxPooling2D((3,3), strides= (1,1), padding = 'same')(input_layer)\n","  path4 = Conv2D(filters = f4, kernel_size = (1,1), padding = 'same', activation = 'relu')(path4)\n","\n","  output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n","\n","  return output_layer"],"metadata":{"id":"Ikj5JiALQ3Cv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def GoogLeNet():\n","  # input layer \n","  input_layer = Input(shape = (256, 256, 3))\n","  X = BatchNormalization()(input_layer)\n","\n","\n","  X = Conv2D(filters = 48, kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu')( X)\n","\n","  X = MaxPooling2D(pool_size = 2, strides = 2)(X)\n","\n","  X = Conv2D(filters = 64, kernel_size = (1,1), strides = 1, padding = 'same', activation = 'relu')(X)\n","\n","  X = Conv2D(filters = 96, kernel_size = (3,3), padding = 'same', activation = 'relu')(X)\n","\n","  X = MaxPooling2D(pool_size= 2, strides = 2)(X)\n","\n","  # 1st Inception block\n","  X = Inception_block(X, f1 = 32, f2_conv1 = 48, f2_conv3 = 64, f3_conv1 = 16, f3_conv5 = 16, f4 = 16)\n","\n","  # 2nd Inception block\n","  X = Inception_block(X, f1 = 64, f2_conv1 = 64, f2_conv3 = 96, f3_conv1 = 16, f3_conv5 = 48, f4 = 32)\n","\n","  X = MaxPooling2D(pool_size= 2, strides = 2)(X)\n","\n","  # 3rd Inception block\n","  X = Inception_block(X, f1 = 96, f2_conv1 = 48, f2_conv3 = 104, f3_conv1 = 16, f3_conv5 = 24, f4 = 32)\n","\n","  # Extra network 1:\n","  X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n","  X1 = Conv2D(filters = 64, kernel_size = (1,1), padding = 'same', activation = 'relu')(X1)\n","  X1 = Flatten()(X1)\n","  X1 = Dense(128, activation = 'relu')(X1)\n","  X1 = Dropout(0.2)(X1)\n","  X1 = Dense(6, activation = 'softmax', name = 'x1')(X1)\n","\n","  \n","  # 4th Inception block\n","  X = Inception_block(X, f1 = 80, f2_conv1 = 56, f2_conv3 = 112, f3_conv1 = 24, f3_conv5 = 32, f4 = 32)\n","\n","  # 5th Inception block\n","  X = Inception_block(X, f1 = 64, f2_conv1 = 64, f2_conv3 = 128, f3_conv1 = 24, f3_conv5 = 32, f4 = 32)\n","\n","  # 6th Inception block\n","  X = Inception_block(X, f1 = 56, f2_conv1 = 112, f2_conv3 = 144, f3_conv1 = 16, f3_conv5 = 32, f4 = 32)\n","\n","  # Extra network 2:\n","  X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n","  X2 = Conv2D(filters = 64, kernel_size = (1,1), padding = 'same', activation = 'relu')(X2)\n","  X2 = Flatten()(X2)\n","  X2 = Dense(128, activation = 'relu')(X2)\n","  X2 = Dropout(0.2)(X2)\n","  X2 = Dense(6, activation = 'softmax', name = 'x2')(X2)\n","  \n","  \n","  # 7th Inception block\n","  X = Inception_block(X, f1 = 128, f2_conv1 = 80, f2_conv3 = 160, f3_conv1 = 16, \n","                      f3_conv5 = 64, f4 = 64)\n","\n","  X = MaxPooling2D(pool_size = 2, strides = 2)(X)\n","\n","  # 8th Inception block\n","  X = Inception_block(X, f1 = 128, f2_conv1 = 80, f2_conv3 = 160, f3_conv1 = 16, f3_conv5 = 64, f4 = 64)\n","\n","  # 9th Inception block\n","  X = Inception_block(X, f1 = 192, f2_conv1 = 96, f2_conv3 = 192, f3_conv1 = 48, f3_conv5 = 64, f4 = 64)\n","\n","  # Global Average pooling layer \n","  X = GlobalAveragePooling2D(name = 'GAPL')(X)\n","\n","  # Dropoutlayer \n","  X = Dropout(0.1)(X)\n","\n","  # output layer \n","  X = Dense(6, activation = 'softmax', name = 'GoogLeNetOutPut')(X)\n","  \n","  # model\n","  model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n","\n","  return model"],"metadata":{"id":"n-so8FN_Qxa-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GoogLeNetModel = GoogLeNet()\n","GoogLeNetModel.summary()"],"metadata":{"id":"wyObvEqBRCBP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GoogLeNetModel.compile(optimizer=Adam(learning_rate=0.001,)\n",",loss=SparseCategoricalCrossentropy() ,metrics=[\"accuracy\"])#,metrics=[\"accuracy\"]"],"metadata":{"id":"nBvRSd7uRpFn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GoogLeNetModel.fit(datagen.flow(X_train, y_train, batch_size=16,),\n","         steps_per_epoch=len(X_train) / 16, epochs=150)"],"metadata":{"id":"Cmx7XhvTglmW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GoogLeNetModel.fit(X_train, y_train, batch_size=64, epochs=32)"],"metadata":{"id":"RbLpe2dLRrqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GoogLeNetModel.save('models/v_6')"],"metadata":{"id":"x5dvBiaQY0ze"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GoogLeNetModel = models.load_model('models/v_6')"],"metadata":{"id":"jWtC-9VLY58V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Ptrain = GoogLeNetModel.predict(X_train)\n","Ptrain= Ptrain[0]\n","s1 = np.sum(np.argmax(Ptrain, axis=1) == y_train[:,0])/Ptrain.shape[0]\n","\n","# del Ptrain\n","# del X_train\n","# del y_train\n","s1"],"metadata":{"id":"bIXnOXprRtZ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Ptest = GoogLeNetModel.predict(X_test)\n","Ptest= Ptest[0]\n","s2 = np.sum(np.argmax(Ptest, axis=1) == y_test[:,0])/Ptest.shape[0]\n","\n","# del Ptest\n","# del X_test\n","# del y_test\n","s2"],"metadata":{"id":"U74rzYFORxPv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imgsP2 = glob.glob(f\"./NN_DataSet/Test/*\")\n","TestImgs = []\n","testID = []\n","# x = 500 , y = 700\n","for f in imgsP2:\n","  img = cv2.imread(f)\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  img = img.astype(np.float32)\n","  img = cv2.resize(img, (256,256), interpolation = cv2.INTER_AREA)\n","\n","\n","  img /= 255\n","  TestImgs.append(img)\n","  testID.append(f.split('/')[3])\n","\n","TestImgs = np.array(TestImgs)\n","del imgsP2"],"metadata":{"id":"HTS2JGBAi_0k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tests = GoogLeNetModel.predict(TestImgs)\n","tests=tests[0]\n","tests = np.argmax(tests, axis=1)\n","col1 = pd.DataFrame(testID,columns=[\"image_name\"]).reset_index(drop=True)\n","col2 = pd.DataFrame(tests,columns=[\"label\"]).reset_index(drop=True)\n","sub = pd.concat([col1,col2],axis=1)#.reset_index(drop=True)\n","sub.to_csv(\"./submission6.csv\",index=False)"],"metadata":{"id":"r0c6DvJRTwms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i=55\n","\n","plt.title(str(tests[i]))\n","plt.imshow(TestImgs[i,:])"],"metadata":{"id":"_ouf4v0rT1gN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i=230\n","\n","plt.title(str(tests[i]))\n","plt.imshow(TestImgs[i,:])"],"metadata":{"id":"dUnxv3GJT3OL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7rVYWnoBUrw6"},"execution_count":null,"outputs":[]}]}